---
title: "House's Debate Analysis"
author: "Xinyuan Li & Philipp Weisenburger"
date: "2023-12-07"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Cleaning


```{r data_cleaning}
#House's Debate Analysis
rm(list = ls())

#Install the stm package
#install.packages("stm")

#Load the package 
library(stm)

#Load the data
setwd("C:/Users/scene/Documents/R/GIRI/project")

# read text and basic cleaning
speeches_paths <- c("data/hein-daily/speeches_107.txt",
                    "data/hein-daily/speeches_107.txt",
                    "data/hein-daily/speeches_108.txt",
                    "data/hein-daily/speeches_108.txt",
                    "data/hein-daily/speeches_109.txt",
                    "data/hein-daily/speeches_110.txt",
                    "data/hein-daily/speeches_110.txt",
                    "data/hein-daily/speeches_110.txt",
                    "data/hein-daily/speeches_111.txt",
                    "data/hein-daily/speeches_112.txt")

maps_paths <- c("data/hein-daily/107_SpeakerMap.txt",
                "data/hein-daily/107_SpeakerMap.txt",
                "data/hein-daily/108_SpeakerMap.txt",
                "data/hein-daily/108_SpeakerMap.txt",
                "data/hein-daily/109_SpeakerMap.txt",
                "data/hein-daily/110_SpeakerMap.txt",
                "data/hein-daily/110_SpeakerMap.txt",
                "data/hein-daily/110_SpeakerMap.txt",
                "data/hein-daily/111_SpeakerMap.txt",
                "data/hein-daily/112_SpeakerMap.txt")
speech_list <- list()
map_list <- list()
data_list <- list()
speech_line <- list(c(25349,89),
                 c(113464,203),
                 c(22078,231),
                 c(131692,266),
                 c(14950,182),
                 c(9917,115),
                 c(127081,32),
                 c(170707,65),
                 c(69547,64),
                 c(22559,231)
                 )


# House speeches for ten fiscal years
for (i in 1:3){
  column_names <- read.table(speeches_paths[i], sep = "|", nrows = 1, header = FALSE)
  speech_list[[i]] <- read.table(speeches_paths[i], sep = "|", 
                               skip = speech_line[[i]][1], nrows = speech_line[[i]][2], header = FALSE)
  colnames(speech_list[[i]]) <- as.character(unlist(column_names))
  map_list[[i]] <- read.delim(maps_paths[i], sep = "|", header = TRUE)
  data_list[[i]] <- merge(speech_list[[i]], map_list[[i]], by = "speech_id", all.x = TRUE)
}

column_names <- read.table(speeches_paths[3], sep = "|", nrows = 1, header = FALSE)
speech3a <- read.table(speeches_paths[3], sep = "|", 
                             skip = 20215, nrows = 220, header = FALSE)
colnames(speech3a) <- as.character(unlist(column_names))
map3a <- read.delim(maps_paths[3], sep = "|", header = TRUE)
data3a <- merge(speech3a, map3a, by = "speech_id", all.x = TRUE)

for (i in 4:10){
  column_names <- read.table(speeches_paths[i], sep = "|", nrows = 1, header = FALSE)
  speech_list[[i]] <- read.table(speeches_paths[i], sep = "|", 
                                 skip = speech_line[[i]][1], nrows = speech_line[[i]][2], header = FALSE)
  colnames(speech_list[[i]]) <- as.character(unlist(column_names))
  map_list[[i]] <- read.delim(maps_paths[i], sep = "|", header = TRUE)
  data_list[[i]] <- merge(speech_list[[i]], map_list[[i]], by = "speech_id", all.x = TRUE)
}

#merge

data <- rbind(
  cbind(data_list[[1]], year = "2002", crisis='non-crisis'),
  cbind(data_list[[2]], year = "2003", crisis='non-crisis'),
  cbind(data_list[[3]], year = "2004", crisis='non-crisis'),
  cbind(data3a, year = "2004", crisis='non-crisis'),
  cbind(data_list[[4]], year = "2005", crisis='non-crisis'),
  cbind(data_list[[5]], year = "2006", crisis='crisis'),
  cbind(data_list[[6]], year = "2007", crisis='crisis'),
  cbind(data_list[[7]], year = "2008", crisis='crisis'),
  cbind(data_list[[8]], year = "2009", crisis='crisis'),
  cbind(data_list[[9]], year = "2010", crisis='crisis'),
  cbind(data_list[[10]], year = "2011", crisis='non-crisis'))

data<- na.omit(data)

saveRDS(data, file = "data/data_house.rds")


#Clean text data
data <- readRDS(file = "data/data_house.rds")
processed<- textProcessor(data$speech, #the column that has the text 
                          metadata = data, #the name of data set
                          lowercase=TRUE, removestopwords=TRUE, removenumbers=TRUE,  
                          removepunctuation=TRUE, stem=TRUE, 
                          wordLengths=c(3,Inf),  #remove words shorter than 3 letters
                          sparselevel=1, language="en",  verbose=TRUE, 
                          onlycharacter= FALSE, striphtml=FALSE, 
                          customstopwords=c("economic","economics","economical","economies","economy",
                                            "america","america’s","american","americans",
                                            "speaker","can","minute", "minutes","gentleman","gentlewoman",
                                            "just","now","time","madam","miss",
                                            "will","that","ladies","gentlemen",
                                            "take","what","there","across",
                                            "one","year","want","back","say",
                                            "yea","nay","get","rollcall","aye","noe",
                                            "yield","chairman","committee","committees",
                                            "amendment","amendments","amend","amends","amending",
                                            "budget","member","members", "vote","votes",
                                            "voter","voters", "house", "rule",
                                            "come","let","resolution", "debate", "debates", 
                                            "thank", "ask", "asks", "asking", 
                                            "distinguish", "distinguished", "may", 
                                            "question","questions", "work", "works", "working", 
                                            "bill","bills","congress", "congressional",
                                            "process", "senate","senator","senators",
                                            "side","sides", "friend","friends", 
                                            "know","known","knowing","knows", 
                                            "colleague","colleagues", "think","thinks","thinking",
                                            "unanimous","unanimously",
                                            "caucus","caucuses", "make","makes")) #custom stopwords

saveRDS(processed, file = "data/processed_house.rds")

```

## STM


```{r stm}
#House's Debate Analysis
rm(list = ls())

#Install the stm package
#install.packages("stm")

#Load the package 
library(stm)

#Load the data
setwd("C:/Users/scene/Documents/R/GIRI/project")
processed <- readRDS(file = "data/processed_house.rds")

#Now we separate our data into neat bits for our analysis 
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <-out$meta

# Find the best K value
set.seed(2008)
findingk <- searchK(out$documents, out$vocab, 
                    K = c(19:21), 
                    prevalence =~ crisis * party, #topic prevalence 
                    data = meta, verbose=FALSE)


#Fit a model with our given k and topic prevalence and content equations

set.seed(2008)
First_STM <- stm(documents = out$documents, vocab = out$vocab,
                 K = 20, 
                 prevalence =~ crisis * party, 
                 max.em.its =75, data = out$meta,init.type = "Spectral", 
                 verbose = FALSE)

#We built the model!
saveRDS(First_STM, file = "data/First_STM_house.rds")
#Now we analyze it
First_STM <- readRDS(file = "data/First_STM_house.rds")

#First, we identify topics and interpret them


#Plot the most prevalent topics in this model
par(mar=c(2,2,2,2))
plot(First_STM)

sageLabels(First_STM,n=10)
sink("output/sageLabels-selected.txt", append=FALSE, split=TRUE)
print(sageLabels(First_STM,n=10))
sink()

#Now that we understand topics, we can see if their prevalence differs based on certain factors


#Specify a model that assesses the prevalence of topics 
prep <- estimateEffect(c(1:20) ~ crisis * party,
                       First_STM,meta = meta, uncertainty = "Global")
saveRDS(prep, file = "data/prep_house.rds")
```

## Analysis


```{r analysis}
#House's Debate Analysis
rm(list = ls())

#Install the stm package
#install.packages("stm")
#install.packages("igraph")

#Load the package 
library(stm)
library(igraph)
library(ggplot2)
library(dplyr)

set.seed(2008)
#Load the data
setwd("C:/Users/scene/Documents/R/GIRI/project")
First_STM <- readRDS(file = "data/First_STM_house.rds")
prep <- readRDS(file = "data/prep_house.rds")
processed <- readRDS(file = "data/processed_house.rds")

#Now we separate our data into neat bits for our analysis 
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <-out$meta
meta$year <- as.integer(meta$year)

topic_number = c(5,8,19,18,10,2,14,13,4,7)
topic_labels = c("Topic 5 – Fiscal Policy", 
                  "Topic 8 – Technology regulations", 
                  "Topic 19 – Balanced budget", 
                  "Topic 18 – Defense (?)", 
                  "Topic 10 – Budget technicalities", 
                  "Topic 2 – Social Security and Medicare", 
                  "Topic 14 – Education and Veterans", 
                  "Topic 13 – Corporate taxation", 
                  "Topic 4 – Government Shutdown", 
                  "Topic 7 – Energy sector" )

#Now we plot the effect of CRISIS
Sys.setlocale(locale="en_US.UTF-8")
plot(prep, 
     covariate = "crisis", 
     topics = topic_number,
     model = First_STM, method = "difference", 
     cov.value1 = 'crisis', 
     cov.value2 = 'non-crisis', 
     xlab = "Non-Crisis ... Crisis", 
     main = "Effect of Non-Crisis vs. Crisis", 
     xlim = c(-.25, .25),
     labeltype = "custom", 
     custom.labels = topic_labels
     ) 

#Now we plot the effect of PARTY
plot(prep, 
     covariate = "party",
     topics = topic_number,
     model = First_STM, method = "difference", 
     cov.value1 = 'R', 
     cov.value2 = 'D', 
     xlab = "Democratic ... Republican", 
     main = "Effect of Democratic vs. Republican",
     xlim = c(-.2, .2),
     labeltype = "custom", 
     custom.labels = topic_labels
     ) 

#Trend of top topics
topic_distributions <- First_STM$theta
topic_distribution_with_year <- cbind(meta$year, topic_distributions)
topic_distribution_df <- as.data.frame(topic_distributions)
topic_distribution_df$year = meta$year

for (i in seq_along(topic_number)) {
  topic_index <- topic_number[i]
  topic_label <- topic_labels[i]
  yearly_distribution <- topic_distribution_df %>%
    group_by(year) %>%
    summarise(Average = mean(get(paste0("V", topic_index))))
  p <- ggplot(yearly_distribution, aes(x = year, y = Average)) +
    geom_line() +
    geom_point() +
    scale_x_continuous(breaks = yearly_distribution$year) +
    labs(x = "Fiscal Year", y = "Average Topic Distribution",
         title = paste("Trend of", topic_label)) +
    theme_classic()
  ggsave(filename = paste0("t", topic_index, ".png"), plot = p, width = 6, height = 4)
}

#Speech Count by States
meta_count <- meta %>% count(state) %>% filter(n > 15) %>% arrange(desc(n))
ggplot(meta_count, aes(x = reorder(state, n), y = n)) +
  geom_bar(stat = "identity") +
  labs(x = "State", y = "Speech Count (>15)") +
  coord_flip() +
  theme_classic()

```